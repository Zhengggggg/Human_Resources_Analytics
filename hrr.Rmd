---
title: "Human Resources Analytics"
author: "Ng Jia Waie"
date: "December 30, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggvis)
library(corrplot)
library(DT)
library(caret)
library(radarchart)
data <- read.csv(file = "HR_comma_sep.csv")
colnames(data)[names(data) == "sales"] <- "department"
colnames(data)[names(data) == "time_spend_company"] <- "years_spent_in_company"
colnames(data)[names(data) == "left"] <- "left_job"
colnames(data)[names(data) == "average_montly_hours"] <- "average_monthly_hours"
```
##Data Collection
This dataset is related to the record of the employees in the company. This dataset contains 14999 rows and 10 columns. The dataset describes the satisfaction level of the company, last evaluation of their performance, number of projects they done, their average monthly working hours, the number of years spent in the company, whether the employee had a workplace accident, whether the employee left the workspace, their last promotion, the sales and the salary level.
<hr>

##Characteristic & Sumarry of Dataset 
In this figure below, it shows the correlation of each variables with few example of record. For example, each employee work on 3 to 4 projects in a year with around 200 hours per month.
```{r}
str(data)
summary(data)
head(data)
corrplot(cor(data[,1:8]), method="circle")
```
<hr>


##Data Preprocessing {.tabset .tabset-fade .tabset-pills}
In this section, we will transform raw data into an understandable format where raw data often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors.


###Data Transformation {.tabset}
We had done some transformation on the dataset, below is the code that we had perform and result will be in check for outliner which under data cleaning.
```{r eval=FALSE}
preprocessParams <- preProcess(data[,1:8], method=c("range"))
normData <- predict(preprocessParams, data[,1:8])

```
<hr>

###Data Cleaning {.tabset}
We had done some data cleaning works such as remove duplicate data, check for NA and check for outliner. 

####Correct Inconsistent Data
In the figure below contain some preprocessing work that we had done.
```{r eval=FALSE}
colnames(data)[names(data) == "sales"] <- "department"
colnames(data)[names(data) == "time_spend_company"] <- "years_spent_in_company"
colnames(data)[names(data) == "left"] <- "left_job"
colnames(data)[names(data) == "average_montly_hours"] <- "average_monthly_hours"
```
<br>
Current dataset will be look like this:
```{r echo=FALSE}
head(data)
```
<hr>

####Remove Duplicate
Previously, we have 14999 record.
```{r echo=FALSE}
dim(data)
```
Duplicate record :
```{r echo=FALSE}
sum(duplicated(data))
data <- data[!duplicated(data),]
```
After remove duplicate entries, we had left 11991 record.
```{r echo=FALSE}
dim(data)
```
<hr>

####Check For NA
We had also check for any not available value contain in each variable
```{r}
any(is.na(data))
```
Since there isn't any NA contain in the dataset, hence no imputation required.
<br>
<hr>

####Check For Outlier
We had check for outlier in each column of data set for both before normalize and after normalize and result will be shown below:
<br>
<br>
Below is the graph of outlier before normalize:
```{r, echo=FALSE}
default <- par("mar")
par(mar=c(10,11,3,1))
preprocessParams <- preProcess(data[,1:8], method=c("range"))
normData <- predict(preprocessParams, data[,1:8])
boxplot(data[1:5], names = names(data[1:5]), las = 2, col = c("#7E57C2","#42A5F5","#9CCC65","#EA80FC","#EC407A"), horizontal = T, main="Checking for outliers (Data without normalizing)")
```

Below is the graph of outlier after normalize:
```{r, echo=FALSE, }
default <- par("mar")
par(mar=c(10,11,3,1))
boxplot(normData[1:5], names = names(normData[1:5]), las = 2, col = c("#7E57C2","#42A5F5","#9CCC65","#EA80FC","#EC407A"), horizontal = T, main="Checking for outliers (Data normalized)")
par(mar=default)
```
Although that we based on the graph above show that years spent in company contain some outlier, but after examine the code below, we conclude that those outlier is valid for the variable.
```{r eval=FALSE}
(outliers <- levels(factor(boxplot.stats(data[,'years_spent_in_company'])$out)))
(oriValues <- levels(factor(data[,'years_spent_in_company'])))
```
<br>
<br>
<hr>


###Data Reduction {.tabset}
After we remove duplicate record, we found out that our record isn't very big. We decided not to do data sampling due to if we sampling the data, and it might affect our data analysis part.
<br>
<strong>Sampling data in our case is optional.<strong>
<hr>


##Data Analysis
In the figure below, we had done some analysis steps to get meaningful information from the dataset.


###Satisfaction Level
   In this part, we want to found out relationship between Satisfaction Level and people who left job and we found out that those who left have low satisfaction level contain the most compare other satisfaction level.

```{r echo=FALSE}
hr_hist <- data %>% filter(left_job==1)
hist(hr_hist$satisfaction_level,col="#3090C7", main = "Satisfaction level : left job")
```




#Answer for Part 1 Assignment
A.	Describe the dataset
<br>
This dataset is related to the record of the employees in the company. This dataset contains 14999 rows and 10 columns. The dataset describes the satisfaction level of the company, last evaluation of their performance, number of projects they done, their average monthly working hours, the number of years spent in the company, whether the employee had a workplace accident, whether the employee left the workspace, their last promotion, the sales and the salary level. We had found out that some of the column names are too ambiguous, for example, the column "last_evaluation" does not give a clear meaning. Besides, the data unit of the column is ambiguous, for example, the column name "time_spend_company" is recorded in integers values (3,4,5), however, it could represent anything, and in this case, represents unit years. Another problem that we found in this dataset is that true and false are represented as 1 and 0 instead. 
<br>
<br>
B.	Insight
<br>
The insight that we wish to extract from this dataset is the next employee who will likely leave the company. We want to find out how to keep employees satisfied.  
<br>
<br>
C.	Data Mining Technique
<br>
The data mining technique that will be relevant is classification, by analysing the dataset we can find out what kind of employees are likely to leave the company.  For example, we can look in the satisfaction level, the number of projects and salary rate to determine whether the employee will leave or stay in the company. Another data mining technique that we wish to apply is association rule. For example, we can discover someone with the different level of salary across the different department that will have a high likelihood of leaving the company.
<br>
<br>
D.	Data quality issues
<br>
After checking the dataset against the six data qualities dimension which is uniqueness, timeliness, completeness, consistency, accuracy, and validity, we found out that the dataset contains duplicate entry and may need processing. Besides, some of the column names do not properly describe its content such that:
<br>
-	time_spend_company - the column name didn't specify the data unit
<br>
-	last_evalution - we do not know what the column name is trying to imply.
<br>
-	Sales - the column name is not relevant to the values.
<br>
-	average_montly_hours - Spelling Error




